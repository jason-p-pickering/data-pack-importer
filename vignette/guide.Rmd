---
title: "Tier II Data Validation Guide"
author: "Jason P. Pickering, David Huser"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tier II Data Validation Guide}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Tier II Data Validation Guide

This manual should guide through the Tier II DataPack / DisaggTool process for COP18.

**Status: DRAFT**

### Set up your environment

- Follow the instructions here: [data-pack-importer-vagrant](https://github.com/davidhuser/data-pack-importer-vagrant)
- Check for updates to the `prod` branch. To update your environment with the latest code changes, run in RStudio:

```{r eval=FALSE}
devtools::install_github('jason-p-pickering/data-pack-importer', ref='prod')
```

### Reveive and download the country DisaggTools

They are Excel spreadsheets either attached to the Datim Support Zendesk or links to Sharepoint files. Download those into the repository from above. The country team *needs to indicate* the distribution method that should be used, either it's 2017 (FY17 Results) or 2018 (FY18 Targets).

### DisaggTool validation

Run a first validation. Adjust the following code and paste it into RStudio code (http://localhost:8787) and hit `ENTER`.

```{r eval=FALSE}
# ADJUST THIS --->
disagg_tool_file="DisaggTool_filename.xlsx"
distribution_year=2017

# DO NOT CHANGE
support_files="/vagrant/support_files/"
disagg_tools="/vagrant/disagg_tools/"
library(devtools)
library(datapackimporter)
disagg_tool=paste0(disagg_tools, disagg_tool_file)
wb<-disagg_tool
wb
psnu_data<-ImportSheets(wb, distribution_method = distribution_year, support_files_path = support_files)
prepare_export_to_datim(psnu_data)
cat(toJSON(psnu_data, auto_unbox = TRUE), file = psnu_json_file)
site_data<-distributeSite(psnu_data)
export_site_level_tool(site_data)
```

It creates the following files:

- `SiteLevelReview_*.xlsx` -> send back to the country team via Datim Support. There may be errors, *include that log* into your response so the country team can correct their Disagg Tools and re-submit it. Re-run the DisaggTool validation.
- `*_import_*.csv` -> depending of issues, continue to run _Import File Validation_ or act as below.


**TBD**

Issue handling:

- *Hard stop:* Tier II does not proceed with anything else until this is fixed by the country team.
- *Continue:* Tier II proceeds with validation #2 of the `*_import_*.csv`

Possible issues and their consequences:

- Negative values: *hard stop*
- Schema not valid: *hard stop*
- DisAggTool corrupted: *hard stop*
- Missing PSNUs: *continue*


### Import File Validation

In above step a CSV file was generated. This step checks if it is a valid DATIM import file. See these instructions for doing so: https://github.com/jason-p-pickering/datim-validation/blob/master/vignettes/validating_data.Rmd

If the validation passes, reroute file to Tier III.

If it does not pass, respond with the logs to the country team.